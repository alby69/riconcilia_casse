# Accounting Reconciliation Web Service

This project provides a powerful and flexible accounting reconciliation service, accessible via a web interface or as a batch processing script. It allows users to upload financial data, apply sophisticated matching algorithms, and generate detailed reports.

## ‚ú® Key Features

- **Intuitive Web Interface**: A clean, tab-organized UI for uploading files and customizing processing settings.
- **Multiple Algorithms**: Supports various reconciliation algorithms, including "Simple" (1-to-1) and "Subset Sum" (N-to-1), selectable by the user.
- **Dynamic Configuration**: Allows real-time modification of key parameters like tolerance, time windows, and search strategies directly from the browser.
- **Secure In-Memory Processing**: Files are processed in memory to ensure speed and data privacy, without permanently storing sensitive data.
- **Detailed Excel Reports**: The output is a multi-sheet Excel file that includes:
  - A **Summary** sheet with parameters and high-level results.
  - A sheet with all **Matches** found.
  - Sheets for **Unreconciled Debit** and **Unreconciled Credit** transactions.
  - Detailed processing **Statistics**.
  - A **Monthly Balance** analysis with a visual chart.
- **Batch Processing**: A command-line script (`batch.py`) to process multiple files automatically.
- **Parameter Optimizer**: A script (`optimizer.py`) to find the optimal reconciliation parameters for a given dataset.
- **Production & Docker Ready**: Containerized with Docker and ready for production deployment using a Gunicorn WSGI server.
- **Modular Architecture**: Core logic separated from reporting and UI for better maintainability.

## ‚öôÔ∏è Installation

1.  **Prerequisites**: Python 3.9+ and Git.

2.  **Clone the Repository**:
    ```bash
    git clone <YOUR_REPOSITORY_URL>
    cd accounting-reconciliation
    ```

3.  **Create and Activate a Virtual Environment**:
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # On Windows, use: .venv\Scripts\activate
    ```

4.  **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

## üê≥ Usage with Docker

The recommended way to run the application is with Docker Compose, which simplifies building the image and managing containers.

### Using Docker Compose

1.  **Build and Start the Service**:
    ```bash
    docker compose up -d --build
    ```
    The application will be accessible at `http://localhost:5000`.

2.  **View Logs**:
    ```bash
    docker compose logs -f
    ```

3.  **Stop the Service**:
    ```bash
    docker compose down
    ```

## üöÄ How to Use the Web Application

The primary way to use the application is through the web interface, which is started using Docker Compose as described above.

The service runs on a Gunicorn WSGI server, configured for production use. The configuration is handled automatically by the `start.sh` script inside the Docker container:
- **Workers**: The number of worker processes is set dynamically to `(2 * CPU cores) + 1` for optimal performance.
- **Timeout**: A timeout of 300 seconds is configured to allow for long-running optimization and processing tasks without interruptions.

### Output Generato

Per ogni file elaborato:
```
output/
‚îú‚îÄ‚îÄ risultato_supermercato_A.xlsx  ‚Üê Foglio Excel completo
‚îú‚îÄ‚îÄ risultato_supermercato_B.xlsx
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ batch_log_[timestamp].json     ‚Üê Log dettagliato JSON
    ‚îî‚îÄ‚îÄ riepilogo_[timestamp].csv      ‚Üê Tabella riepilogo
```

### Esempio Output Console

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          BATCH PROCESSOR - ELABORAZIONE MULTIPLA           ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üîç Ricerca file in: input
‚úì Trovati 3 file da elaborare

‚öôÔ∏è  CONFIGURAZIONE:
   - Tolleranza: ‚Ç¨0.01
   - Finestra temporale: ¬±30 giorni
   - Max combinazioni: 6
   - Output: output/

[1/3] ============================================================
üìÇ Elaborazione: supermercato_A.xlsx
============================================================
  ‚è≥ Caricamento dati...
  ‚úì Caricati 850 movimenti
  Movimenti DARE: 320, AVERE: 530
  ‚è≥ Riconciliazione in corso...

  ‚úÖ COMPLETATO
  üìä DARE riconciliati: 305/320 (95.3%)
  üìä AVERE utilizzati: 498/530 (94.0%)
  üíæ Salvato in: risultato_supermercato_A.xlsx

[2/3] ============================================================
...

============================================================
üìä RIEPILOGO GLOBALE
============================================================
‚úì File elaborati con successo: 3/3
‚úó File con errori: 0
‚è±  Tempo totale: 45.3 secondi (0.8 minuti)

üìà STATISTICHE AGGREGATE:
   - Totale movimenti DARE: 1,240
   - DARE riconciliati: 1,180 (95.2%)

üíæ Log salvato in: output/logs/
============================================================
```

### File Log JSON

Il file `batch_log_[timestamp].json` contiene:

```json
{
  "timestamp": "2025-01-15T14:30:22",
  "configurazione": {
    "tolleranza": 0.01,
    "giorni_finestra": 30,
    "max_combinazioni": 6
  },
  "risultati": [
    {
      "file": "supermercato_A.xlsx",
      "successo": true,
      "statistiche": {
        "totale_dare": 320,
        "dare_riconciliati": 305,
        "percentuale_dare": 95.3,
        "output_file": "output/risultato_supermercato_A.xlsx"
      }
    }
  ]
}
```

### File Riepilogo CSV

Tabella analisi rapida per Excel/analisi:

| File | Successo | totale_dare | dare_riconciliati | percentuale_dare |
|------|----------|-------------|-------------------|------------------|
| supermercato_A.xlsx | True | 320 | 305 | 95.3 |
| supermercato_B.xlsx | True | 450 | 430 | 95.6 |
| supermercato_C.xlsx | True | 470 | 445 | 94.7 |

### Pattern Avanzati

**Elabora solo file specifici:**
```python
'pattern': 'supermercato_*.xlsx'  # Solo file che iniziano con "supermercato_"
'pattern': '*_gennaio_2025.xlsx'  # Solo file di gennaio
'pattern': 'store_[0-9]*.xlsx'    # Solo store con numero
```

**Cartelle separate per periodo:**
```python
config = {
    'cartella_input': 'dati/gennaio_2025',
    'cartella_output': 'risultati/gennaio_2025',
}
```

### Automazione con Cron/Task Scheduler

**Linux/Mac (cron):**
```bash
# Esegui ogni giorno alle 2:00 AM
0 2 * * * cd /percorso/progetto && python batch_processor.py >> batch.log 2>&1
```

**Windows (Task Scheduler):**
```
Azione: Avvia programma
Programma: python.exe
Argomenti: batch_processor.py
Cartella di avvio: C:\percorso\progetto
```

### Gestione Errori

Se alcuni file falliscono, il batch continua con gli altri:

```
[2/5] ============================================================
üìÇ Elaborazione: file_con_colonne_errate.xlsx
============================================================
  ‚ùå ERRORE: Il file deve contenere le colonne: Data, Dare, Avere

[3/5] ============================================================
üìÇ Elaborazione: file_ok.xlsx
============================================================
  ‚úÖ COMPLETATO
...

‚ö†Ô∏è  FILE CON ERRORI:
   - file_con_colonne_errate.xlsx: Nome colonna 'Incasso' non trovato. Controllare il file di configurazione.
```

### Integrazione con Script Esterni

**Esportare solo statistiche:**
```python
from batch_processor import BatchProcessor

processor = BatchProcessor(config)
processor.elabora_tutti()

# Accedi a statistiche
for stat in processor.stats_globali:
    print(f"{stat['file']}: {stat['statistiche']['percentuale_dare']}%")
```

**Callback personalizzati:**
```python
class BatchProcessorCustom(BatchProcessor):
    def elabora_file(self, file_path):
        risultato = super().elabora_file(file_path)
        
        # Invia email se errori
        if not risultato['successo']:
            self.invia_alert(risultato['file'], risultato['errore'])
        
        return risultato
```

---

## ‚öôÔ∏è Configurazione via File JSON (Consigliato)

Per una maggiore flessibilit√†, √® possibile gestire tutti i parametri tramite un file esterno `config.json` senza modificare il codice Python.

**1. Crea un file `config.json`** nella stessa cartella degli script con questo contenuto:

```json
{
  "tolleranza": 0.01,
  "giorni_finestra": 30,
  "max_combinazioni": 6,
  "cartella_input": "input",
  "cartella_output": "output",
  "pattern": [
    "*.xlsx",
    "*.csv"
  ]
}
```

**2. Esegui lo script `batch.py`**: Lo script rilever√† automaticamente il file `config.json` e utilizzer√† i valori specificati. Se il file non viene trovato, verranno utilizzati i parametri di default.

---

## üìû Supporto

Per domande o problemi, contatta: [tua-email@esempio.com]

---

## üìÇ Project Structure & File Explanation

Here is an overview of the key files in the project and how they interact:

### Core Logic
- **`core.py`**: The heart of the application. Contains the `ReconciliationEngine` class which implements the reconciliation algorithms (Subset Sum, Progressive Balance) and manages the data flow.
- **`reporting.py`**: Handles the generation of the multi-sheet Excel report. It extracts data from the engine and formats it into a user-friendly Excel file with charts and statistics, adhering to the Single Responsibility Principle.
- **`config.json`**: The central configuration file. Defines parameters like tolerance, column mapping, and algorithm choice.

### Interfaces
- **`app.py`**: The Flask web application. Manages the web interface, file uploads, and API endpoints. It instantiates `ReconciliationEngine` to process uploaded files.
- **`riconciliazione.py`**: The batch processing script. It reads all files in the `input/` folder and processes them sequentially using the settings in `config.json`. Ideal for bulk processing.
- **`main.py`**: A command-line wrapper for single-file execution. Useful for integration with other tools or specific one-off runs.
- **`optimizer.py`**: An advanced script using `Optuna` to automatically find the best parameters (tolerance, window, etc.) for a specific dataset to maximize the reconciliation rate.

### Infrastructure & Docs
- **`docker-compose.yml`**: Defines the Docker service configuration, including volume mounts for live code updates.
- **`templates/index.html`**: The frontend HTML/JS for the web interface.
- **`doc/`**: Folder containing documentation and tutorials (e.g., Git guide).

### How they connect
1.  **User Input**: The user interacts via Web (`app.py`) or Batch Script (`riconciliazione.py`).
2.  **Configuration**: Both interfaces load settings from `config.json`.
3.  **Processing**: The input data is passed to `core.py` (`ReconciliationEngine`).
4.  **Reporting**: Once processed, `core.py` delegates the creation of the Excel file to `reporting.py`.

---

## üìú Changelog

### v3.1.0 (Febbraio 2026)
- **Optimizer**: Aggiunta la `sorting_strategy` allo spazio di ricerca per testare diverse strategie di ordinamento.
- **Gunicorn**: Ottimizzato l'avvio in Docker con worker dinamici (`(2 * core) + 1`) e timeout aumentato per gestire elaborazioni lunghe.
- **Multiprocessing**: Reso stabile il parallelismo di Optuna in Docker tramite l'uso di uno storage SQLite temporaneo.
- **Reporting**: Migliorata la leggibilit√† del grafico "Monthly Performance" con colori distinti per i volumi totali e utilizzati.
- **Bug Fixes**: Corretti diversi errori relativi all'importazione, alla gestione dei parametri e all'esecuzione dell'ottimizzatore.

### v3.0.0 (Versione Corrente)
- **Docker**: Aggiunto supporto ufficiale con `Dockerfile` e `.dockerignore`.
- **Core Engine**: Riscrittura completa del motore (`core.py`) utilizzando **Pandas DataFrame** per performance elevate.
- **Testing**: Nuova suite di test in `tests/` con script di automazione `run_tests.sh`.
- **Refactoring**: Spostamento utility in `tools/` e pulizia del codice.
- **Logging**: Controllo granulare sul salvataggio dei log (parametro `save_log`).
- **Best Fit**: Migliorata la logica di abbinamento parziale con opzione per disabilitarla.
